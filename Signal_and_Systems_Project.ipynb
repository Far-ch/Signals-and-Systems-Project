{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4oSxqB7xPy78eHD8qqXLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Far-ch/Signals-and-Systems-Project/blob/main/Signal_and_Systems_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#YOLO\n",
        "from ultralytics import YOLO\n",
        "import cv2, torch, numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "VIDEO_IN  = \"person1.mp4\"\n",
        "SNAPSHOT  = \"first_detected.jpg\"\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL  = \"yolov8m.pt\"\n",
        "model  = YOLO(MODEL).to(DEVICE)\n",
        "CLASSES = {\n",
        "    0: \"person\",1: \"bicycle\",2: \"car\",3: \"motorcycle\",4: \"airplane\",5: \"bus\",6: \"train\",7: \"truck\",8: \"boat\",9: \"traffic light\",10: \"fire hydrant\",\n",
        "11: \"stop sign\", 12: \"parking meter\",13: \"bench\",14: \"bird\",15: \"cat\",16: \"dog\",17: \"horse\",18: \"sheep\",19: \"cow\",20: \"elephant\",21: \"bear\",\n",
        "22: \"zebra\",23: \"giraffe\",24: \"backpack\",25: \"umbrella\",26: \"handbag\",27: \"tie\",28: \"suitcase\",29: \"frisbee\",30: \"skis\",31: \"snowboard\",32: \"sports ball\",\n",
        "33: \"kite\",34: \"baseball bat\",35: \"baseball glove\",36: \"skateboard\",37: \"surfboard\",38: \"tennis racket\",39: \"bottle\",40: \"wine glass\",41: \"cup\",\n",
        "42: \"fork\",43: \"knife\",44: \"spoon\",45: \"bowl\",46: \"banana\",47: \"apple\",48: \"sandwich\",49: \"orange\",50: \"broccoli\",51: \"carrot\",\n",
        "52: \"hot dog\", 53: \"pizza\",54: \"donut\",55: \"cake\",56: \"chair\",57: \"couch\",58: \"potted plant\",59: \"bed\",60: \"dining table\",61: \"toilet\",\n",
        "62: \"tv\",63: \"laptop\",64: \"mouse\",65: \"remote\",66: \"keyboard\",67: \"cell phone\",68: \"microwave\",69: \"oven\",70: \"toaster\",71: \"sink\",72: \"refrigerator\",\n",
        "73: \"book\",74: \"clock\",75: \"vase\",76: \"scissors\",77: \"teddy bear\",78: \"hair drier\",79: \"toothbrush\"}\n",
        "\n",
        "CLASS_IDS = list(CLASSES.keys())\n",
        "rng = np.random.default_rng(42)\n",
        "COLORS = {cls_id: tuple(rng.integers(64, 256, 3).tolist()) for cls_id in CLASS_IDS}\n",
        "\n",
        "BOX_THICK = 3\n",
        "FONT_SCALE = 1.0\n",
        "FONT_THICK = 2\n",
        "\n",
        "\n",
        "def detect(img_rgb, imgsz=960, conf=0.3):\n",
        "    \"\"\"Detect objects and return list of boxes: (x1, y1, x2, y2, class_id, conf)\"\"\"\n",
        "    res = model.predict(img_rgb, imgsz=imgsz, conf=conf,\n",
        "                        classes=CLASS_IDS, device=DEVICE,\n",
        "                        verbose=False)[0]\n",
        "    out = []\n",
        "    for b in res.boxes:\n",
        "        out.append((*map(int, b.xyxy[0]), int(b.cls[0]), float(b.conf[0])))\n",
        "    return out\n",
        "\n",
        "\n",
        "def robust_detect(frame_bgr):\n",
        "    H, W = frame_bgr.shape[:2]\n",
        "\n",
        "    #Full-frame\n",
        "    boxes = detect(cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB), 1280, 0.3)\n",
        "    if boxes:\n",
        "        return boxes\n",
        "\n",
        "    #Center crop + upscale\n",
        "    cw, ch = int(W * 0.6), int(H * 0.7)\n",
        "    x0, y0 = (W - cw) // 2, (H - ch) // 2\n",
        "    crop = frame_bgr[y0:y0+ch, x0:x0+cw]\n",
        "    crop_up = cv2.resize(crop, (1280, 1280))\n",
        "    boxes_crop = detect(cv2.cvtColor(crop_up, cv2.COLOR_BGR2RGB), 1280, 0.25)\n",
        "    if boxes_crop:\n",
        "        sx, sy = cw / 1280, ch / 1280\n",
        "        return [(int(x1*sx + x0), int(y1*sy + y0),\n",
        "                 int(x2*sx + x0), int(y2*sy + y0), cls, conf)\n",
        "                for x1, y1, x2, y2, cls, conf in boxes_crop]\n",
        "\n",
        "    #Sliding tiles\n",
        "    out = []\n",
        "    tile, stride = 640, 320\n",
        "    for y in range(0, H, stride):\n",
        "        for x in range(0, W, stride):\n",
        "            tile_bgr = frame_bgr[y:y+tile, x:x+tile]\n",
        "            boxes_tile = detect(cv2.cvtColor(tile_bgr, cv2.COLOR_BGR2RGB), 640, 0.25)\n",
        "            for x1, y1, x2, y2, cls, conf in boxes_tile:\n",
        "                out.append((x1+x, y1+y, x2+x, y2+y, cls, conf))\n",
        "    return out\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(VIDEO_IN)\n",
        "ok, frame = cap.read()\n",
        "cap.release()\n",
        "assert ok, f\" Couldn't read first frame of {VIDEO_IN}\"\n",
        "\n",
        "boxes = robust_detect(frame.copy())\n",
        "for x1, y1, x2, y2, cls, conf in boxes:\n",
        "    label_name = CLASSES.get(cls, \"unknown\")\n",
        "    label_text = f\"{label_name} {conf:.2f}\"\n",
        "\n",
        "    color = COLORS.get(cls, (0, 255, 255))\n",
        "    cv2.rectangle(frame, (x1, y1), (x2, y2), color, BOX_THICK)\n",
        "\n",
        "    (tw, th), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                  FONT_SCALE, FONT_THICK)\n",
        "    cv2.rectangle(frame, (x1, y1 - th - 8), (x1 + tw, y1), color, -1)\n",
        "    cv2.putText(frame, label_text, (x1, y1 - 5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE,\n",
        "                (255, 255, 255), FONT_THICK, cv2.LINE_AA)\n",
        "\n",
        "\n",
        "cv2.imwrite(SNAPSHOT, frame)\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "73hPLvv5OYkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fast-R-CNN\n",
        "!pip -q install --upgrade torch torchvision torchaudio\n",
        "import cv2, torch, matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models, transforms\n",
        "\n",
        "# COCO classes\n",
        "CLASSES = {\n",
        "    0:\"background\", 1:\"person\", 2:\"bicycle\", 3:\"car\", 4:\"motorcycle\", 5:\"airplane\",\n",
        "    6:\"bus\",7:\"train\",8:\"truck\",9:\"boat\",10:\"trafficlight\",11:\"firehydrant\",\n",
        "    13:\"bench\",14:\"bird\",15:\"cat\",16:\"dog\",17:\"horse\",18:\"sheep\",19:\"cow\",\n",
        "    20:\"elephant\",21:\"bear\",22:\"zebra\",23:\"giraffe\",24:\"backpack\",25:\"umbrella\",\n",
        "    27:\"handbag\",28:\"tie\",31:\"snowboard\",32:\"sportsball\",33:\"kite\",34:\"baseballbat\",\n",
        "    35:\"baseballglove\",36:\"skateboard\",37:\"surfboard\",38:\"tennisracket\",39:\"bottle\",\n",
        "    40:\"wineglass\",41:\"cup\",42:\"fork\",43:\"knife\",44:\"spoon\",45:\"bowl\",46:\"banana\",\n",
        "    47:\"apple\",48:\"sandwich\",49:\"orange\",50:\"broccoli\",51:\"carrot\",52:\"hotdog\",\n",
        "    53:\"pizza\",54:\"donut\",55:\"cake\",56:\"chair\",57:\"couch\",58:\"pottedplant\",59:\"bed\",\n",
        "    60:\"diningtable\",61:\"toilet\",62:\"tv\",63:\"laptop\",64:\"mouse\",65:\"remote\",\n",
        "    66:\"keyboard\",67:\"cellphone\",68:\"microwave\",69:\"oven\",70:\"toaster\",71:\"sink\",\n",
        "    72:\"refrigerator\",73:\"book\",74:\"clock\",75:\"vase\",76:\"scissors\",77:\"teddybear\",\n",
        "    78:\"hairdrier\",79:\"toothbrush\"\n",
        "}\n",
        "\n",
        "VIDEO_PATH = \"person1.mp4\"\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "ok, frame_bgr = cap.read()\n",
        "cap.release()\n",
        "assert ok, \"Could not read first frame\"\n",
        "\n",
        "frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model  = models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "model.to(device).eval()\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])   # converts to [0,1] + CHW\n",
        "img_tensor = transform(frame_rgb).to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model([img_tensor])[0]   # dict with boxes, labels, scores\n",
        "\n",
        "boxes   = preds[\"boxes\"].cpu().numpy()\n",
        "labels  = preds[\"labels\"].cpu().numpy()\n",
        "scores  = preds[\"scores\"].cpu().numpy()\n",
        "\n",
        "CONF_TH = 0.50\n",
        "keep = scores >= CONF_TH\n",
        "\n",
        "boxes, labels, scores = boxes[keep], labels[keep], scores[keep]\n",
        "\n",
        "OUT = frame_bgr.copy()\n",
        "for (x1,y1,x2,y2), cls_id, conf in zip(boxes, labels, scores):\n",
        "    cls_id = int(cls_id)\n",
        "    name   = CLASSES.get(cls_id, f\"id{cls_id}\")\n",
        "    label  = f\"{name} {conf:.2f}\"\n",
        "\n",
        "    color = (0,255,0)   # green boxes; change if you like\n",
        "    cv2.rectangle(OUT, (int(x1),int(y1)), (int(x2),int(y2)), color, 2)\n",
        "    (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
        "    cv2.rectangle(OUT, (int(x1), int(y1)-th-8), (int(x1)+tw, int(y1)), color, -1)\n",
        "    cv2.putText(OUT, label, (int(x1), int(y1)-4),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
        "\n",
        "cv2.imwrite(\"fast_rcnn_detect.jpg\", OUT[:, :, ::-1])  # BGR→RGB file\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.imshow(cv2.cvtColor(OUT, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fast-R-CNN detection \")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LmYF8EyTPOEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KCF\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "cap = cv2.VideoCapture('person4.mp4')\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps_input = cap.get(cv2.CAP_PROP_FPS)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output.mp4', fourcc, fps_input, (width, height))\n",
        "\n",
        "trackers = []\n",
        "labels = []\n",
        "frame_count = 0\n",
        "yolo_ran = False  # برای کنترل اینکه YOLO فقط یک بار اجرا شود\n",
        "\n",
        "total_start = time.perf_counter()\n",
        "window_start = total_start\n",
        "window_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "    window_count += 1\n",
        "    now = time.perf_counter()\n",
        "    elapsed_window = now - window_start\n",
        "\n",
        "    if not yolo_ran:\n",
        "        # فقط یک بار YOLO اجرا می‌شود (اینجا در اولین فریم)\n",
        "        # classes=[2] برای ماشین\n",
        "        results = model.predict(source=frame, conf=0.3,\n",
        "                                max_det=2, classes=[0, 3], verbose=False)[0]\n",
        "        boxes = results.boxes.xyxy.cpu().numpy()\n",
        "        classes = results.boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "        for box, cls in zip(boxes, classes):\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            tracker = cv2.TrackerKCF_create()\n",
        "            bbox = (x1, y1, x2 - x1, y2 - y1)\n",
        "            tracker.init(frame, bbox)\n",
        "            trackers.append(tracker)\n",
        "\n",
        "            label = model.names.get(cls, 'Unknown')\n",
        "            labels.append(label)\n",
        "\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.6, (0, 255, 0), 2)\n",
        "\n",
        "        yolo_ran = True  # علامت می‌زنیم که YOLO اجرا شد\n",
        "    else:\n",
        "        # فقط آپدیت Tracker ها\n",
        "        new_trackers = []\n",
        "        new_labels = []\n",
        "\n",
        "        for tracker, label in zip(trackers, labels):\n",
        "            success, bbox = tracker.update(frame)\n",
        "            if success:\n",
        "                new_trackers.append(tracker)\n",
        "                new_labels.append(label)\n",
        "\n",
        "                x, y, w, h = map(int, bbox)\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "                cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.6, (0, 255, 0), 2)\n",
        "\n",
        "        trackers = new_trackers\n",
        "        labels = new_labels\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "    if elapsed_window >= 0.5:\n",
        "        window_fps = window_count / elapsed_window\n",
        "        print(\n",
        "            f\"FPS in last {elapsed_window:.2f}s (~0.5s window): {window_fps:.2f}\")\n",
        "        window_start = now\n",
        "        window_count = 0\n",
        "\n",
        "total_end = time.perf_counter()\n",
        "elapsed_total = total_end - total_start\n",
        "average_fps = frame_count / elapsed_total\n",
        "print(\n",
        "    f\"Processed {frame_count} frames in {elapsed_total:.2f}s => Average FPS: {average_fps:.2f}\")\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "f0Bv_fyLSGR-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}