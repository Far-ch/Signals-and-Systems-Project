{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Far-ch/Signals-and-Systems-Project/blob/main/Signal_and_Systems_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#YOLO\n",
        "from ultralytics import YOLO\n",
        "import cv2, torch, numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "VIDEO_IN  = \"person1.mp4\"\n",
        "SNAPSHOT  = \"first_detected.jpg\"\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL  = \"yolov8m.pt\"\n",
        "model  = YOLO(MODEL).to(DEVICE)\n",
        "CLASSES = {\n",
        "    0: \"person\",1: \"bicycle\",2: \"car\",3: \"motorcycle\",4: \"airplane\",5: \"bus\",6: \"train\",7: \"truck\",8: \"boat\",9: \"traffic light\",10: \"fire hydrant\",\n",
        "11: \"stop sign\", 12: \"parking meter\",13: \"bench\",14: \"bird\",15: \"cat\",16: \"dog\",17: \"horse\",18: \"sheep\",19: \"cow\",20: \"elephant\",21: \"bear\",\n",
        "22: \"zebra\",23: \"giraffe\",24: \"backpack\",25: \"umbrella\",26: \"handbag\",27: \"tie\",28: \"suitcase\",29: \"frisbee\",30: \"skis\",31: \"snowboard\",32: \"sports ball\",\n",
        "33: \"kite\",34: \"baseball bat\",35: \"baseball glove\",36: \"skateboard\",37: \"surfboard\",38: \"tennis racket\",39: \"bottle\",40: \"wine glass\",41: \"cup\",\n",
        "42: \"fork\",43: \"knife\",44: \"spoon\",45: \"bowl\",46: \"banana\",47: \"apple\",48: \"sandwich\",49: \"orange\",50: \"broccoli\",51: \"carrot\",\n",
        "52: \"hot dog\", 53: \"pizza\",54: \"donut\",55: \"cake\",56: \"chair\",57: \"couch\",58: \"potted plant\",59: \"bed\",60: \"dining table\",61: \"toilet\",\n",
        "62: \"tv\",63: \"laptop\",64: \"mouse\",65: \"remote\",66: \"keyboard\",67: \"cell phone\",68: \"microwave\",69: \"oven\",70: \"toaster\",71: \"sink\",72: \"refrigerator\",\n",
        "73: \"book\",74: \"clock\",75: \"vase\",76: \"scissors\",77: \"teddy bear\",78: \"hair drier\",79: \"toothbrush\"}\n",
        "\n",
        "CLASS_IDS = list(CLASSES.keys())\n",
        "rng = np.random.default_rng(42)\n",
        "COLORS = {cls_id: tuple(rng.integers(64, 256, 3).tolist()) for cls_id in CLASS_IDS}\n",
        "\n",
        "BOX_THICK = 3\n",
        "FONT_SCALE = 1.0\n",
        "FONT_THICK = 2\n",
        "\n",
        "\n",
        "def detect(img_rgb, imgsz=960, conf=0.3):\n",
        "    \"\"\"Detect objects and return list of boxes: (x1, y1, x2, y2, class_id, conf)\"\"\"\n",
        "    res = model.predict(img_rgb, imgsz=imgsz, conf=conf,\n",
        "                        classes=CLASS_IDS, device=DEVICE,\n",
        "                        verbose=False)[0]\n",
        "    out = []\n",
        "    for b in res.boxes:\n",
        "        out.append((*map(int, b.xyxy[0]), int(b.cls[0]), float(b.conf[0])))\n",
        "    return out\n",
        "\n",
        "\n",
        "def robust_detect(frame_bgr):\n",
        "    H, W = frame_bgr.shape[:2]\n",
        "\n",
        "    #Full-frame\n",
        "    boxes = detect(cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB), 1280, 0.3)\n",
        "    if boxes:\n",
        "        return boxes\n",
        "\n",
        "    #Center crop + upscale\n",
        "    cw, ch = int(W * 0.6), int(H * 0.7)\n",
        "    x0, y0 = (W - cw) // 2, (H - ch) // 2\n",
        "    crop = frame_bgr[y0:y0+ch, x0:x0+cw]\n",
        "    crop_up = cv2.resize(crop, (1280, 1280))\n",
        "    boxes_crop = detect(cv2.cvtColor(crop_up, cv2.COLOR_BGR2RGB), 1280, 0.25)\n",
        "    if boxes_crop:\n",
        "        sx, sy = cw / 1280, ch / 1280\n",
        "        return [(int(x1*sx + x0), int(y1*sy + y0),\n",
        "                 int(x2*sx + x0), int(y2*sy + y0), cls, conf)\n",
        "                for x1, y1, x2, y2, cls, conf in boxes_crop]\n",
        "\n",
        "    #Sliding tiles\n",
        "    out = []\n",
        "    tile, stride = 640, 320\n",
        "    for y in range(0, H, stride):\n",
        "        for x in range(0, W, stride):\n",
        "            tile_bgr = frame_bgr[y:y+tile, x:x+tile]\n",
        "            boxes_tile = detect(cv2.cvtColor(tile_bgr, cv2.COLOR_BGR2RGB), 640, 0.25)\n",
        "            for x1, y1, x2, y2, cls, conf in boxes_tile:\n",
        "                out.append((x1+x, y1+y, x2+x, y2+y, cls, conf))\n",
        "    return out\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(VIDEO_IN)\n",
        "ok, frame = cap.read()\n",
        "cap.release()\n",
        "assert ok, f\" Couldn't read first frame of {VIDEO_IN}\"\n",
        "\n",
        "boxes = robust_detect(frame.copy())\n",
        "for x1, y1, x2, y2, cls, conf in boxes:\n",
        "    label_name = CLASSES.get(cls, \"unknown\")\n",
        "    label_text = f\"{label_name} {conf:.2f}\"\n",
        "\n",
        "    color = COLORS.get(cls, (0, 255, 255))\n",
        "    cv2.rectangle(frame, (x1, y1), (x2, y2), color, BOX_THICK)\n",
        "\n",
        "    (tw, th), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                  FONT_SCALE, FONT_THICK)\n",
        "    cv2.rectangle(frame, (x1, y1 - th - 8), (x1 + tw, y1), color, -1)\n",
        "    cv2.putText(frame, label_text, (x1, y1 - 5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE,\n",
        "                (255, 255, 255), FONT_THICK, cv2.LINE_AA)\n",
        "\n",
        "\n",
        "cv2.imwrite(SNAPSHOT, frame)\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "73hPLvv5OYkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fast-R-CNN\n",
        "!pip -q install --upgrade torch torchvision torchaudio\n",
        "import cv2, torch, matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import models, transforms\n",
        "\n",
        "# COCO classes\n",
        "CLASSES = {\n",
        "    0:\"background\", 1:\"person\", 2:\"bicycle\", 3:\"car\", 4:\"motorcycle\", 5:\"airplane\",\n",
        "    6:\"bus\",7:\"train\",8:\"truck\",9:\"boat\",10:\"trafficlight\",11:\"firehydrant\",\n",
        "    13:\"bench\",14:\"bird\",15:\"cat\",16:\"dog\",17:\"horse\",18:\"sheep\",19:\"cow\",\n",
        "    20:\"elephant\",21:\"bear\",22:\"zebra\",23:\"giraffe\",24:\"backpack\",25:\"umbrella\",\n",
        "    27:\"handbag\",28:\"tie\",31:\"snowboard\",32:\"sportsball\",33:\"kite\",34:\"baseballbat\",\n",
        "    35:\"baseballglove\",36:\"skateboard\",37:\"surfboard\",38:\"tennisracket\",39:\"bottle\",\n",
        "    40:\"wineglass\",41:\"cup\",42:\"fork\",43:\"knife\",44:\"spoon\",45:\"bowl\",46:\"banana\",\n",
        "    47:\"apple\",48:\"sandwich\",49:\"orange\",50:\"broccoli\",51:\"carrot\",52:\"hotdog\",\n",
        "    53:\"pizza\",54:\"donut\",55:\"cake\",56:\"chair\",57:\"couch\",58:\"pottedplant\",59:\"bed\",\n",
        "    60:\"diningtable\",61:\"toilet\",62:\"tv\",63:\"laptop\",64:\"mouse\",65:\"remote\",\n",
        "    66:\"keyboard\",67:\"cellphone\",68:\"microwave\",69:\"oven\",70:\"toaster\",71:\"sink\",\n",
        "    72:\"refrigerator\",73:\"book\",74:\"clock\",75:\"vase\",76:\"scissors\",77:\"teddybear\",\n",
        "    78:\"hairdrier\",79:\"toothbrush\"\n",
        "}\n",
        "\n",
        "VIDEO_PATH = \"person1.mp4\"\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "ok, frame_bgr = cap.read()\n",
        "cap.release()\n",
        "assert ok, \"Could not read first frame\"\n",
        "\n",
        "frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model  = models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "model.to(device).eval()\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])   # converts to [0,1] + CHW\n",
        "img_tensor = transform(frame_rgb).to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model([img_tensor])[0]   # dict with boxes, labels, scores\n",
        "\n",
        "boxes   = preds[\"boxes\"].cpu().numpy()\n",
        "labels  = preds[\"labels\"].cpu().numpy()\n",
        "scores  = preds[\"scores\"].cpu().numpy()\n",
        "\n",
        "CONF_TH = 0.50\n",
        "keep = scores >= CONF_TH\n",
        "\n",
        "boxes, labels, scores = boxes[keep], labels[keep], scores[keep]\n",
        "\n",
        "OUT = frame_bgr.copy()\n",
        "for (x1,y1,x2,y2), cls_id, conf in zip(boxes, labels, scores):\n",
        "    cls_id = int(cls_id)\n",
        "    name   = CLASSES.get(cls_id, f\"id{cls_id}\")\n",
        "    label  = f\"{name} {conf:.2f}\"\n",
        "\n",
        "    color = (0,255,0)   # green boxes; change if you like\n",
        "    cv2.rectangle(OUT, (int(x1),int(y1)), (int(x2),int(y2)), color, 2)\n",
        "    (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
        "    cv2.rectangle(OUT, (int(x1), int(y1)-th-8), (int(x1)+tw, int(y1)), color, -1)\n",
        "    cv2.putText(OUT, label, (int(x1), int(y1)-4),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
        "\n",
        "cv2.imwrite(\"fast_rcnn_detect.jpg\", OUT[:, :, ::-1])  # BGRâ†’RGB file\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.imshow(cv2.cvtColor(OUT, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fast-R-CNN detection \")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LmYF8EyTPOEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KCF_Tracker\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import uuid\n",
        "from pathlib import Path\n",
        "\n",
        "# Paths\n",
        "downloads = Path.home() / \"Downloads\"\n",
        "video_path = downloads / \"videos\" / \"person1.mp4\"  # â† change to your file if needed\n",
        "output_path = downloads / \"output.mp4\"\n",
        "\n",
        "# Parameters\n",
        "YOLO_PERIOD = 5\n",
        "IOU_MATCH = 0.5\n",
        "IOU_MERGE = 0.45\n",
        "CONFIDENCE = 0.15\n",
        "MIN_AREA_FRAC = 0.01\n",
        "SPEED_THRESH = 20\n",
        "ROI_SCALE_FAST = 1.4\n",
        "HIST_THRESH = 0.6\n",
        "MAX_MISSES = 30\n",
        "MEMORY_AGE = 300\n",
        "HIST_BINS = (16, 16, 16)\n",
        "\n",
        "# --- Helper functions ---\n",
        "def iou(b1, b2):\n",
        "    xA = max(b1[0], b2[0])\n",
        "    yA = max(b1[1], b2[1])\n",
        "    xB = min(b1[2], b2[2])\n",
        "    yB = min(b1[3], b2[3])\n",
        "    inter = max(0, xB - xA) * max(0, yB - yA)\n",
        "    if inter == 0: return 0.0\n",
        "    a1 = (b1[2] - b1[0]) * (b1[3] - b1[1])\n",
        "    a2 = (b2[2] - b2[0]) * (b2[3] - b2[1])\n",
        "    return inter / (a1 + a2 - inter)\n",
        "\n",
        "def hsv_hist(img, bins=HIST_BINS):\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    h = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
        "    cv2.normalize(h, h)\n",
        "    return h.flatten()\n",
        "\n",
        "def hist_corr(h1, h2):\n",
        "    return cv2.compareHist(h1.astype(np.float32), h2.astype(np.float32), cv2.HISTCMP_CORREL)\n",
        "\n",
        "def create_kalman(cx, cy):\n",
        "    kf = cv2.KalmanFilter(4, 2)\n",
        "    kf.transitionMatrix = np.array([[1, 0, 1, 0],\n",
        "                                     [0, 1, 0, 1],\n",
        "                                     [0, 0, 1, 0],\n",
        "                                     [0, 0, 0, 1]], np.float32)\n",
        "    kf.measurementMatrix = np.eye(2, 4, dtype=np.float32)\n",
        "    kf.processNoiseCov = np.eye(4, dtype=np.float32) * 1e-2\n",
        "    kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 1e-1\n",
        "    kf.statePre = np.array([[cx], [cy], [0], [0]], np.float32)\n",
        "    kf.statePost = kf.statePre.copy()\n",
        "    return kf\n",
        "\n",
        "# Load model\n",
        "model = YOLO('yolov8m.pt')  # more accurate than yolov8n.pt\n",
        "\n",
        "cap = cv2.VideoCapture(str(video_path))\n",
        "if not cap.isOpened():\n",
        "    raise FileNotFoundError(f\"Cannot open: {video_path}\")\n",
        "\n",
        "W = int(cap.get(3))\n",
        "H = int(cap.get(4))\n",
        "fps_in = cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "out = cv2.VideoWriter(str(output_path), cv2.VideoWriter_fourcc(*'mp4v'), fps_in, (W, H))\n",
        "min_area = MIN_AREA_FRAC * (W * H)\n",
        "\n",
        "tracks = []\n",
        "lost = []\n",
        "frame_idx = 0\n",
        "t0 = time.perf_counter()\n",
        "\n",
        "# Main loop\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_idx += 1\n",
        "\n",
        "    for tr in tracks:\n",
        "        pred = tr[\"kalman\"].predict()\n",
        "        px, py = pred[0], pred[1]\n",
        "        enlarge = ROI_SCALE_FAST if tr[\"speed\"] > SPEED_THRESH else 1.0\n",
        "\n",
        "        success, bbox = tr[\"tracker\"].update(frame)\n",
        "        if not success:\n",
        "            tr[\"miss\"] += 1\n",
        "            w = tr[\"box\"][2] - tr[\"box\"][0]\n",
        "            h = tr[\"box\"][3] - tr[\"box\"][1]\n",
        "            w *= enlarge\n",
        "            h *= enlarge\n",
        "            x1, y1 = int(px - w / 2), int(py - h / 2)\n",
        "            x2, y2 = int(px + w / 2), int(py + h / 2)\n",
        "            tr[\"box\"] = [max(0, x1), max(0, y1), min(W - 1, x2), min(H - 1, y2)]\n",
        "        else:\n",
        "            x, y, w, h = map(int, bbox)\n",
        "            cx, cy = x + w // 2, y + h // 2\n",
        "            tr[\"kalman\"].correct(np.array([[cx], [cy]], np.float32))\n",
        "            dx, dy = cx - tr[\"cx\"], cy - tr[\"cy\"]\n",
        "            tr[\"speed\"] = float(np.hypot(dx, dy))\n",
        "            tr[\"cx\"], tr[\"cy\"] = cx, cy\n",
        "            tr[\"box\"] = [x, y, x + w, y + h]\n",
        "            tr[\"miss\"] = 0\n",
        "            patch = frame[y:y + h, x:x + w]\n",
        "            if patch.size:\n",
        "                tr[\"hist\"] = 0.8 * tr[\"hist\"] + 0.2 * hsv_hist(patch)\n",
        "\n",
        "    tracks = [tr for tr in tracks if tr[\"miss\"] <= MAX_MISSES or lost.append({\n",
        "        \"id\": tr[\"id\"], \"label\": tr[\"label\"], \"hist\": tr[\"hist\"], \"last\": frame_idx\n",
        "    }) is None]\n",
        "    lost = [lt for lt in lost if frame_idx - lt[\"last\"] <= MEMORY_AGE]\n",
        "\n",
        "    if frame_idx % YOLO_PERIOD == 0 or any(tr[\"miss\"] > 0 for tr in tracks):\n",
        "        res = model.predict(frame, conf=CONFIDENCE, verbose=False)[0]\n",
        "        dets = res.boxes.xyxy.cpu().numpy().astype(int)\n",
        "        cls = res.boxes.cls.cpu().numpy().astype(int)\n",
        "        dets = [(x1, y1, x2, y2, int(c)) for (x1, y1, x2, y2), c in zip(dets, cls)\n",
        "                if (x2 - x1) * (y2 - y1) > min_area]\n",
        "\n",
        "        matched = set()\n",
        "        for tr in tracks:\n",
        "            best_iou, best_j = 0, -1\n",
        "            for j, (x1, y1, x2, y2, cid) in enumerate(dets):\n",
        "                if j in matched:\n",
        "                    continue\n",
        "                iou_val = iou(tr[\"box\"], (x1, y1, x2, y2))\n",
        "                if iou_val > best_iou:\n",
        "                    best_iou, best_j = iou_val, j\n",
        "            if best_iou > IOU_MATCH:\n",
        "                x1, y1, x2, y2, cid = dets[best_j]\n",
        "                trk = cv2.TrackerKCF_create()\n",
        "                trk.init(frame, (x1, y1, x2 - x1, y2 - y1))\n",
        "                cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "                tr.update(dict(tracker=trk, box=[x1, y1, x2, y2],\n",
        "                               cx=cx, cy=cy, miss=0))\n",
        "                matched.add(best_j)\n",
        "\n",
        "        for j, (x1, y1, x2, y2, cid) in enumerate(dets):\n",
        "            if j in matched:\n",
        "                continue\n",
        "            patch = frame[y1:y2, x1:x2]\n",
        "            hh = hsv_hist(patch)\n",
        "            best_score, best_lt = 0, None\n",
        "            for lt in lost:\n",
        "                score = hist_corr(hh, lt[\"hist\"])\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_lt = lt\n",
        "            if best_score > HIST_THRESH:\n",
        "                id_, label = best_lt[\"id\"], best_lt[\"label\"]\n",
        "                lost.remove(best_lt)\n",
        "            else:\n",
        "                id_, label = str(uuid.uuid4())[:8], model.names.get(cid, f\"class{cid}\")\n",
        "            trk = cv2.TrackerKCF_create()\n",
        "            trk.init(frame, (x1, y1, x2 - x1, y2 - y1))\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            tracks.append(dict(id=id_, label=label, tracker=trk,\n",
        "                               box=[x1, y1, x2, y2], hist=hh, miss=0,\n",
        "                               speed=0, cx=cx, cy=cy,\n",
        "                               kalman=create_kalman(cx, cy)))\n",
        "\n",
        "    tracks.sort(key=lambda t: t[\"miss\"])\n",
        "    filtered = []\n",
        "    for tr in tracks:\n",
        "        if any(iou(tr[\"box\"], f[\"box\"]) > IOU_MERGE for f in filtered):\n",
        "            continue\n",
        "        filtered.append(tr)\n",
        "    tracks = filtered\n",
        "\n",
        "    for tr in tracks:\n",
        "        x1, y1, x2, y2 = map(int, tr[\"box\"])\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, tr[\"label\"], (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "# Done\n",
        "elapsed = time.perf_counter() - t0\n",
        "print(f\"Done. Frames: {frame_idx}, Time: {elapsed:.2f}s, Avg FPS: {frame_idx / elapsed:.2f}\")\n",
        "print(f\"Output saved to: {output_path}\")\n",
        "cap.release()\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "f0Bv_fyLSGR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MOSSE_Tracker\n",
        "import time\n",
        "import uuid\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from pathlib import Path\n",
        "\n",
        "#PATHS\n",
        "downloads = Path.home() / \"Downloads\"\n",
        "VIDEO_PATH = downloads / \"videos\" / \"car1.mp4\"\n",
        "OUTPUT_PATH = downloads / \"car1_mosse_final_output.mp4\"\n",
        "\n",
        "#PARAMETERS\n",
        "CONF_TH = 0.5\n",
        "MAX_LOST = 250\n",
        "HIST_THRESH = 0.6\n",
        "HIST_BINS = (16, 16, 16)\n",
        "\n",
        "#COCO LABELS\n",
        "COCO = {i: name for i, name in enumerate([\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', '', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', '', 'backpack', 'umbrella', '', '',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
        "    'tennis racket', 'bottle', '', 'wine glass', 'cup', 'fork', 'knife',\n",
        "    'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli',\n",
        "    'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "    'potted plant', 'bed', '', 'dining table', '', '', 'toilet', '', 'tv',\n",
        "    'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
        "    'oven', 'toaster', 'sink', 'refrigerator', '', 'book', 'clock', 'vase',\n",
        "    'scissors', 'teddy bear', 'hair drier', 'toothbrush'])}\n",
        "\n",
        "#Histogram functions\n",
        "def get_histogram(patch):\n",
        "    hsv = cv2.cvtColor(patch, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv], [0, 1, 2], None, HIST_BINS, [0, 180, 0, 256, 0, 256])\n",
        "    cv2.normalize(hist, hist)\n",
        "    return hist.flatten()\n",
        "\n",
        "def compare_hist(hist1, hist2):\n",
        "    return cv2.compareHist(hist1.astype(np.float32), hist2.astype(np.float32), cv2.HISTCMP_CORREL)\n",
        "\n",
        "#Kalman Filter\n",
        "class KalmanFilter:\n",
        "    def __init__(self, x, y):\n",
        "        self.kf = cv2.KalmanFilter(8, 4)\n",
        "        self.kf.transitionMatrix = np.eye(8, dtype=np.float32)\n",
        "        for i in range(4):\n",
        "            self.kf.transitionMatrix[i, i + 4] = 1\n",
        "        self.kf.measurementMatrix = np.zeros((4, 8), np.float32)\n",
        "        for i in range(4):\n",
        "            self.kf.measurementMatrix[i, i] = 1\n",
        "        self.kf.processNoiseCov = np.eye(8, dtype=np.float32) * 1e-3\n",
        "        self.kf.measurementNoiseCov = np.eye(4, dtype=np.float32) * 1e-2\n",
        "        self.kf.statePost = np.array([[x], [y], [0], [0], [0], [0], [0], [0]], np.float32)\n",
        "\n",
        "    def predict(self):\n",
        "        pred = self.kf.predict()\n",
        "        return int(pred[0, 0]), int(pred[1, 0])\n",
        "\n",
        "    def correct(self, x, y):\n",
        "        self.kf.correct(np.array([[x], [y], [0], [0]], np.float32))\n",
        "\n",
        "#Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\").to(device).eval()\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "#Load video\n",
        "cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
        "assert cap.isOpened(), f\"Cannot open video: {VIDEO_PATH}\"\n",
        "W, H = int(cap.get(3)), int(cap.get(4))\n",
        "fps_in = cap.get(cv2.CAP_PROP_FPS) or 25\n",
        "out = cv2.VideoWriter(str(OUTPUT_PATH), cv2.VideoWriter_fourcc(*'mp4v'), fps_in, (W, H))\n",
        "\n",
        "#Initialize\n",
        "tracks = []\n",
        "frame_idx = 0\n",
        "start_time = time.time()\n",
        "ret, frame = cap.read()\n",
        "frame_idx += 1\n",
        "assert ret, \"Can't read the first frame\"\n",
        "img_tensor = transform(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model([img_tensor])[0]\n",
        "\n",
        "boxes = preds[\"boxes\"].cpu().numpy()\n",
        "labels = preds[\"labels\"].cpu().numpy()\n",
        "scores = preds[\"scores\"].cpu().numpy()\n",
        "\n",
        "for box, cls, score in zip(boxes, labels, scores):\n",
        "    if score < CONF_TH:\n",
        "        continue\n",
        "    x1, y1, x2, y2 = map(int, box)\n",
        "    w, h = x2 - x1, y2 - y1\n",
        "    patch = frame[y1:y2, x1:x2]\n",
        "    if patch.size == 0:\n",
        "        continue\n",
        "    tracker = cv2.legacy.TrackerMOSSE_create()\n",
        "    tracker.init(frame, (x1, y1, w, h))\n",
        "    kalman = KalmanFilter(x1 + w // 2, y1 + h // 2)\n",
        "    hist = get_histogram(patch)\n",
        "    label = COCO.get(int(cls), f\"class{int(cls)}\")\n",
        "    tracks.append({\n",
        "        \"id\": str(uuid.uuid4())[:8],\n",
        "        \"tracker\": tracker,\n",
        "        \"label\": label,\n",
        "        \"kalman\": kalman,\n",
        "        \"hist\": hist,\n",
        "        \"lost\": 0\n",
        "    })\n",
        "    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
        "\n",
        "out.write(frame)\n",
        "\n",
        "#Track across video\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_idx += 1\n",
        "    new_tracks = []\n",
        "\n",
        "    for tr in tracks:\n",
        "        ok, bbox = tr[\"tracker\"].update(frame)\n",
        "        x, y, w, h = map(int, bbox)\n",
        "        x2, y2 = x + w, y + h\n",
        "\n",
        "        if not ok or w <= 0 or h <= 0:\n",
        "            tr[\"lost\"] += 1\n",
        "            pred_x, pred_y = tr[\"kalman\"].predict()\n",
        "            if tr[\"lost\"] <= MAX_LOST:\n",
        "                cv2.circle(frame, (pred_x, pred_y), 4, (255, 255, 0), -1)\n",
        "                new_tracks.append(tr)\n",
        "            continue\n",
        "\n",
        "        patch = frame[y:y+h, x:x+w]\n",
        "        if patch.size > 0:\n",
        "            hist_new = get_histogram(patch)\n",
        "            sim = compare_hist(tr[\"hist\"], hist_new)\n",
        "            if sim >= HIST_THRESH:\n",
        "                tr[\"kalman\"].correct(x + w // 2, y + h // 2)\n",
        "                tr[\"hist\"] = 0.8 * tr[\"hist\"] + 0.2 * hist_new\n",
        "                tr[\"lost\"] = 0\n",
        "            else:\n",
        "                tr[\"lost\"] += 1\n",
        "                if tr[\"lost\"] <= MAX_LOST:\n",
        "                    pred_x, pred_y = tr[\"kalman\"].predict()\n",
        "                    cv2.circle(frame, (pred_x, pred_y), 4, (255, 0, 0), -1)\n",
        "                    new_tracks.append(tr)\n",
        "                continue\n",
        "\n",
        "        cv2.rectangle(frame, (x, y), (x2, y2), (255, 0, 0), 2)\n",
        "        cv2.putText(frame, tr[\"label\"], (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "        new_tracks.append(tr)\n",
        "\n",
        "    tracks = new_tracks\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    fps = frame_idx / elapsed\n",
        "    cv2.putText(frame, f\"FPS: {fps:.1f}\", (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "print(f\"âœ… Done. Output saved to: {OUTPUT_PATH}\")\n",
        "print(f\"ðŸ“ˆ Average FPS: {frame_idx / (time.time() - start_time):.2f}\")"
      ],
      "metadata": {
        "id": "qB1m9Iai_sFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CSRT_Tracker\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def extract_hsv_hist(patch, bins=(16,16,16)):\n",
        "    hsv = cv2.cvtColor(patch, cv2.COLOR_BGR2HSV)\n",
        "    hist = cv2.calcHist([hsv], [0,1,2], None, bins, [0,180,0,256,0,256])\n",
        "    cv2.normalize(hist, hist)\n",
        "    return hist.flatten()\n",
        "\n",
        "def iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    if interArea == 0:\n",
        "        return 0\n",
        "    boxAArea = (boxA[2]-boxA[0]) * (boxA[3]-boxA[1])\n",
        "    boxBArea = (boxB[2]-boxB[0]) * (boxB[3]-boxB[1])\n",
        "    return interArea / float(boxAArea + boxBArea - interArea)\n",
        "\n",
        "class Track:\n",
        "    def __init__(self, bbox, label, frame):\n",
        "        self.tracker = cv2.TrackerCSRT_create()\n",
        "        self.tracker.init(frame, bbox)\n",
        "        x,y,w,h = map(int, bbox)\n",
        "        patch = frame[y:y+h, x:x+w]\n",
        "        self.feature = extract_hsv_hist(patch)\n",
        "        self.label = label\n",
        "        self.miss_count = 0\n",
        "\n",
        "        cx, cy = x + w/2, y + h/2\n",
        "        self.kalman = cv2.KalmanFilter(4,2)\n",
        "        self.kalman.transitionMatrix = np.array([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]], np.float32)\n",
        "        self.kalman.measurementMatrix = np.eye(2,4, dtype=np.float32)\n",
        "        self.kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 1e-2\n",
        "        self.kalman.measurementNoiseCov = np.eye(2, dtype=np.float32) * 1e-1\n",
        "        self.kalman.statePre  = np.array([[cx],[cy],[0],[0]], np.float32)\n",
        "        self.kalman.statePost = self.kalman.statePre.copy()\n",
        "\n",
        "    def predict(self):\n",
        "        return self.kalman.predict()\n",
        "\n",
        "    def correct(self, cx, cy):\n",
        "        self.kalman.correct(np.array([[cx],[cy]], np.float32))\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "cap = cv2.VideoCapture('person4.mp4')\n",
        "W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps_in = cap.get(cv2.CAP_PROP_FPS)\n",
        "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps_in, (W,H))\n",
        "\n",
        "tracks = []\n",
        "frame_idx = 0\n",
        "t_start = time.perf_counter()\n",
        "DETECTION_INTERVAL = 20\n",
        "MAX_MISSES = 10\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_idx += 1\n",
        "\n",
        "    if frame_idx % DETECTION_INTERVAL == 0:\n",
        "        res = model.predict(frame, conf=0.3, classes=[0,3], verbose=False)[0]\n",
        "        boxes = res.boxes.xyxy.cpu().numpy().astype(int)\n",
        "        classes = res.boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "        matches = set()\n",
        "        for box, cls in zip(boxes, classes):\n",
        "            x1,y1,x2,y2 = box\n",
        "            w, h = x2 - x1, y2 - y1\n",
        "            patch = frame[y1:y2, x1:x2]\n",
        "            hist = extract_hsv_hist(patch)\n",
        "\n",
        "            best_match = None\n",
        "            best_score = 0.5\n",
        "            for i, tr in enumerate(tracks):\n",
        "                if i in matches:\n",
        "                    continue\n",
        "                tx,ty,tw,th = tr.tracker.getROI()\n",
        "                tiou = iou([x1,y1,x2,y2], [tx,ty,tx+tw,ty+th])\n",
        "                cosine = np.dot(hist, tr.feature) / (np.linalg.norm(hist)*np.linalg.norm(tr.feature) + 1e-6)\n",
        "                score = 0.5 * tiou + 0.5 * cosine\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_match = i\n",
        "\n",
        "            if best_match is not None:\n",
        "                tr = tracks[best_match]\n",
        "                tr.tracker = cv2.TrackerCSRT_create()\n",
        "                tr.tracker.init(frame, (x1,y1,w,h))\n",
        "                tr.correct(x1 + w/2, y1 + h/2)\n",
        "                tr.feature = 0.7 * tr.feature + 0.3 * hist\n",
        "                tr.miss_count = 0\n",
        "                matches.add(best_match)\n",
        "            else:\n",
        "                tracks.append(Track((x1,y1,w,h), model.names[int(cls)], frame))\n",
        "\n",
        "    # Track update\n",
        "    new_tracks = []\n",
        "    for tr in tracks:\n",
        "        pc = tr.predict()\n",
        "        ok, bbox = tr.tracker.update(frame)\n",
        "        if ok:\n",
        "            x,y,w,h = map(int, bbox)\n",
        "            cx, cy = x + w/2, y + h/2\n",
        "            tr.correct(cx, cy)\n",
        "            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2)\n",
        "            cv2.putText(frame, tr.label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n",
        "            cv2.circle(frame, (int(pc[0]),int(pc[1])), 4, (0,0,255), -1)\n",
        "            tr.miss_count = 0\n",
        "        else:\n",
        "            tr.miss_count += 1\n",
        "\n",
        "        if tr.miss_count < MAX_MISSES:\n",
        "            new_tracks.append(tr)\n",
        "\n",
        "    tracks = new_tracks\n",
        "    out.write(frame)\n",
        "\n",
        "t_end = time.perf_counter()\n",
        "print(f\"Processed {frame_idx} frames in {t_end - t_start:.2f}s â€” Avg FPS: {frame_idx / (t_end - t_start):.2f}\")\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "UtCZThCAChMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}